
import streamlit as st

st.set_page_config(page_title="GÃ©nÃ©rateur de Prompt Expert", layout="centered")

st.title("ğŸ§  GÃ©nÃ©rateur de Prompt Engineering Expert")

st.markdown("""
Ce formulaire t'aide Ã  gÃ©nÃ©rer un **prompt expert structurÃ©** pour ChatGPT ou tout autre LLM.
ComplÃ¨te les champs ci-dessous et gÃ©nÃ¨re un prompt prÃªt Ã  copier.
""")

# Initialisation de session
if "generated_prompt" not in st.session_state:
    st.session_state.generated_prompt = ""

# Form fields
role = st.text_input("Quel est le rÃ´le que doit jouer l'IA ? (ex : juriste, marketeur, dÃ©veloppeur IA)")
public = st.text_input("Pour qui travaille-t-elle ? (ex : TPE mÃ©dia, jeunes 15-25 ans, entreprise en difficultÃ©)")
mission = st.text_area("Quelle est sa mission prÃ©cise ? (ex : crÃ©er une campagne, analyser un contrat...)")
contraintes = st.text_area("Contraintes Ã  respecter (ton, style, durÃ©e, format, droit applicable...)")
format_reponse = st.text_input("Format attendu (ex : tableau, PDF, script Python, etc.)")
question_first = st.checkbox("Demander Ã  lâ€™IA de poser des questions si besoin avant de rÃ©pondre ?", value=True)

# Bouton GÃ©nÃ©rer
if st.button("ğŸ¯ GÃ©nÃ©rer le Prompt"):
    prompt = f"""
Agis en tant que {role} pour {public}.
Ta mission est de {mission}.
Contraintes : {contraintes}.
Donne-moi la rÃ©ponse sous forme de : {format_reponse}.
"""
    if question_first:
        prompt += " Pose-moi des questions si certains Ã©lÃ©ments sont flous avant de gÃ©nÃ©rer la rÃ©ponse."

    st.session_state.generated_prompt = prompt.strip()

# Affichage et actions
if st.session_state.generated_prompt:
    st.subheader("ğŸ“ Prompt GÃ©nÃ©rÃ© :")
    st.text_area("ğŸ“‹ Copie ton prompt ici", value=st.session_state.generated_prompt, height=200, key="display_prompt")

    st.download_button(
        label="â¬‡ï¸ TÃ©lÃ©charger le prompt (.txt)",
        data=st.session_state.generated_prompt,
        file_name="prompt_expert.txt",
        mime="text/plain"
    )

    if st.button("ğŸ§¹ Effacer le Prompt"):
        st.session_state.generated_prompt = ""
        st.experimental_rerun()
